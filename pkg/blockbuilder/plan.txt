# Purpose
blockbuilder is responsible for consuming ingested data in the queue (kafka, etc) and writing it in an optimized form to long term storage. While this should always remain true, it can be built and iterated upon in phases. First, let's look at the simplest possible architecture:

* [interface] loads "jobs": partitions+offset ranges in kafka
* For each job, process data, building the storage format 
* [interface] Upon completion (inc flushing to storage), commit work
  * e.g. update consumer group processed offset in kafka
* consumes 

# First Impl: Alongside existing multi-zone ingester writers
Goal: modify ingester architecture towards RF1, but don't actually write to storage yet, b/c we haven't solved coordinating interim reads/writes.
Deliverable: RF1 metrics proof
* run replicas==partitions (from ingesters)
* run every $INTERVAL (5m?), 
* slim down ingester write path
  * remove disk (all WALs).
  * ignore limits if too complex (for now)
  * /dev/null backend

# Second Impl: Foo

* metadata store
  * include offsets committed for coordination b/w ingester-readers & long term storage
* scheduler architecture
* shuffle sharding