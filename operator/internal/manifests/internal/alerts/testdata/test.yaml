rule_files:
  - ../prometheus-alerts.yaml

evaluation_interval: 1m

tests:
  - interval: 1m

    input_series:
      - series: 'loki_request_duration_seconds_count{status_code="500", namespace="my-ns", job="ingester", route="my-route"}'
        values: '1+1x20'
      - series: 'loki_request_duration_seconds_count{status_code="429", namespace="my-ns", job="ingester", route="my-route"}'
        values: '1+1x20'
      - series: 'loki_request_duration_seconds_count{status_code="200", namespace="my-ns", job="ingester", route="my-route"}'
        values: '1+3x20'
      - series: 'http_requests_total{code="500", namespace="my-ns", job="gateway", handler="push", group="logsv1"}'
        values: '1+1x20'
      - series: 'http_requests_total{code="200", namespace="my-ns", job="gateway", handler="push", group="logsv1"}'
        values: '1+3x20'
      - series: 'http_requests_total{code="500", namespace="my-ns", job="gateway", handler="query", group="logsv1"}'
        values: '1+1x20'
      - series: 'http_requests_total{code="200", namespace="my-ns", job="gateway", handler="query", group="logsv1"}'
        values: '1+3x20'

      - series: 'loki_panic_total{namespace="my-ns", job="ingester"}'
        values: '0 1 1 2+0x10'

      - series: 'loki_ingester_wal_replay_flushing{namespace="my-ns"}'
        values: '1 1 1 2+0x10'

      - series: 'cortex_query_frontend_queue_length{namespace="my-ns"}'
        values: '3 5 2 2+0x10'

    # Unit test for alerting rules.
    alert_rule_test:
      - eval_time: 16m
        alertname: LokiRequestErrors
        exp_alerts:
          - exp_labels:
              namespace: my-ns
              job: ingester
              route: my-route
              severity: critical
            exp_annotations:
              summary: "At least 10% of requests are responded by 5xx server errors."
              message: "ingester my-route is experiencing 20.00% errors."
              runbook_url: "[[ .RunbookURL ]]#Loki-Request-Errors"
      - eval_time: 16m
        alertname: LokiStackWriteRequestErrors
        exp_alerts:
          - exp_labels:
              namespace: my-ns
              job: gateway
              severity: critical
            exp_annotations:
              summary: "At least 10% of write requests to the lokistack-gateway are responded with 5xx server errors."
              message: "25.00% of write requests from gateway are returned with server errors."
              runbook_url: "[[ .RunbookURL ]]#LokiStack-Write-Request-Errors"
      - eval_time: 16m
        alertname: LokiStackReadRequestErrors
        exp_alerts:
          - exp_labels:
              namespace: my-ns
              job: gateway
              severity: critical
            exp_annotations:
              summary: "At least 10% of query requests to the lokistack-gateway are responded with 5xx server errors."
              message: "25.00% of query requests from gateway are returned with server errors."
              runbook_url: "[[ .RunbookURL ]]#LokiStack-Read-Request-Errors"
      - eval_time: 10m
        alertname: LokiRequestPanics
        exp_alerts:
          - exp_labels:
              namespace: my-ns
              job: ingester
              severity: critical
            exp_annotations:
              summary: "A panic was triggered."
              message: "ingester is experiencing an increase of 2 panics."
              runbook_url: "[[ .RunbookURL ]]#Loki-Request-Panics"

      # --------- LokiTenantRateLimit ---------
      - eval_time: 16m
        alertname: LokiTenantRateLimit
        exp_alerts:
          - exp_labels:
              namespace: my-ns
              job: ingester
              route: my-route
              severity: warning
            exp_annotations:
              summary: "At least 10% of requests are responded with the rate limit error code."
              message: "ingester my-route is experiencing 429 errors."
              runbook_url: "[[ .RunbookURL ]]#Loki-Tenant-Rate-Limit"

      # --------- LokiWritePathHighLoad ---------
      - eval_time: 16m
        alertname: LokiWritePathHighLoad
        exp_alerts:
          - exp_labels:
              namespace: my-ns
              severity: warning
            exp_annotations:
              summary: "The write path is experiencing high load, causing backpressure storage flushing."
              message: "The write path is experiencing high load."
              runbook_url: "[[ .RunbookURL ]]#Loki-Write-Path-High-Load"

      # --------- LokiReadPathHighLoad ---------
      - eval_time: 6m
        alertname: LokiReadPathHighLoad
        exp_alerts:
          - exp_labels:
              namespace: my-ns
              severity: warning
            exp_annotations:
              summary: "The query queue is experiencing high load."
              message: "The read path is experiencing high load."
              runbook_url: "[[ .RunbookURL ]]#Loki-Read-Path-High-Load"
